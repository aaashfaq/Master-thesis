{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jr009039': 126, 'jr005882': 236, 'jr003529': 235, 'jr003534': 226, 'jr005667': 241, 'jr009062': 235, 'jr003260': 256, 'jr003803': 98, 'jr005990': 225, 'jr003912': 233, 'jr003376': 204, 'jr003642': 228, 'jr003525': 277, 'jr009032': 183, 'jr003021': 86, 'jr005691': 217}\n",
      "126\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 480), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/usama/lib/python3.10/site-packages/PIL/Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 480), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m augmented_mri_image_np \u001b[38;5;241m=\u001b[39m augmented_mri_image\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Convert the NumPy array to a PIL Image\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m augmented_mri_image_pil \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_mri_image_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m mrt_folder\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(mri_dir,patient_folder)\n\u001b[1;32m     67\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(mrt_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/usama/lib/python3.10/site-packages/PIL/Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3082\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m typekey\n\u001b[0;32m-> 3083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 480), |u1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the paths to your original dataset\n",
    "dataset_dir = '/root/code/thesis/codeFolder/LatestDataInUse'\n",
    "\n",
    "# Create a directory for the balanced dataset\n",
    "balanced_dataset_dir = '/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_range_augmented_CT'\n",
    "os.makedirs(balanced_dataset_dir, exist_ok=True)\n",
    "\n",
    "# Loop through the CT folder to count the number of CT images for each patient\n",
    "ct_counts = {}\n",
    "for patient_folder in os.listdir(os.path.join(dataset_dir, 'Ct2SequencesforMRT')):\n",
    "    ct_counts[patient_folder] = len(os.listdir(os.path.join(dataset_dir, 'Ct2SequencesforMRT', patient_folder)))\n",
    "print(ct_counts)\n",
    "\n",
    "# Create subdirectories for CT and MRI in the balanced dataset directory\n",
    "#ct_dir = os.path.join(balanced_dataset_dir, 'CT')\n",
    "mri_dir = balanced_dataset_dir\n",
    "#os.makedirs(ct_dir, exist_ok=True)\n",
    "os.makedirs(mri_dir, exist_ok=True)\n",
    "\n",
    "# Define a function for data augmentation\n",
    "def augment_image(image):\n",
    "    transform = transforms.Compose([\n",
    "\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.1865, 0.1865, 0.1865], [0.2008, 0.2008, 0.2008]),\n",
    "        transforms.RandomRotation(degrees=(-40, 40)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        # Define your desired transformations here (e.g., rotation, flip, etc.)\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        # Add more transformations as needed\n",
    "        ])\n",
    "    return transform(image)\n",
    "\n",
    "# Loop through the MRI folder, augment MRI images for each patient to match CT image count, and save them\n",
    "for patient_folder in os.listdir('/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_forCT'):\n",
    "    #print(patient_folder)\n",
    "\n",
    "    patient_mri_dir = os.path.join('/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_forCT', patient_folder)\n",
    "    patient_ct_count = ct_counts.get(patient_folder, 0)\n",
    "    print(patient_ct_count)\n",
    "\n",
    "    mri_images = os.listdir(patient_mri_dir)\n",
    "    #print(mri_images)\n",
    "\n",
    "    for i in range(patient_ct_count):\n",
    "\n",
    "        # To handle the case where there are fewer MRI images, use modulo to cycle through the available images.\n",
    "        mri_image = Image.open(os.path.join(patient_mri_dir, mri_images[i % len(mri_images)]))\n",
    "\n",
    "        augmented_mri_image = augment_image(mri_image)\n",
    "        mrt_folder= os.path.join(mri_dir,patient_folder)\n",
    "\n",
    "        os.makedirs(mrt_folder, exist_ok=True)\n",
    "        #augmented_mri_image.save(os.path.join(mrt_folder, f'{i}.png'))\n",
    "\n",
    "        #Convert the augmented_mri_image tensor back to a PIL Image\n",
    "        augmented_mri_image_pil = transforms.ToPILImage()(augmented_mri_image)\n",
    "        \n",
    "        #Save the PIL Image\n",
    "        augmented_mri_image_pil.save(os.path.join(mrt_folder, f'{i}.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jr009039': 126, 'jr005882': 236, 'jr003529': 235, 'jr003534': 226, 'jr005667': 241, 'jr009062': 235, 'jr003260': 256, 'jr003803': 98, 'jr005990': 225, 'jr003912': 233, 'jr003376': 204, 'jr003642': 228, 'jr003525': 277, 'jr009032': 183, 'jr003021': 86, 'jr005691': 217}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to your original dataset\n",
    "dataset_dir = '/root/code/thesis/codeFolder/LatestDataInUse/Combining'\n",
    "\n",
    "# Create a directory for the balanced dataset\n",
    "balanced_dataset_dir = '/root/code/thesis/codeFolder/LatestDataInUse/Combining/t2_hr_spir_numpy_Augmented'\n",
    "os.makedirs(balanced_dataset_dir, exist_ok=True)\n",
    "\n",
    "# Loop through the CT folder to count the number of CT images for each patient\n",
    "ct_counts = {}\n",
    "for patient_folder in os.listdir(os.path.join(dataset_dir, 'CT2SequencesnumpyforMRT')):\n",
    "    ct_counts[patient_folder] = len(os.listdir(os.path.join(dataset_dir, 'CT2SequencesnumpyforMRT', patient_folder)))\n",
    "print(ct_counts)\n",
    "\n",
    "# Create a directory for MRI images\n",
    "mri_dir = balanced_dataset_dir\n",
    "os.makedirs(mri_dir, exist_ok=True)\n",
    "\n",
    "# Define a function for data augmentation\n",
    "def augment_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(-40, 40)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        # Add more transformations as needed\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "# Loop through the MRI folder, augment MRI images for each patient to match CT image count, and save them\n",
    "for patient_folder in os.listdir('/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_numpy_augmentCT'):\n",
    "    patient_mri_dir = os.path.join('/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_numpy_augmentCT', patient_folder)\n",
    "    patient_ct_count = ct_counts.get(patient_folder, 0)\n",
    "\n",
    "    mri_images = os.listdir(patient_mri_dir)\n",
    "\n",
    "    for i in range(patient_ct_count):\n",
    "        mri_image = np.load(os.path.join(patient_mri_dir, mri_images[i % len(mri_images)]))\n",
    "\n",
    "        mri_image = Image.fromarray(mri_image)\n",
    "        augmented_mri_image = augment_image(mri_image)\n",
    "        mrt_folder= os.path.join(mri_dir, patient_folder)\n",
    "        os.makedirs(mrt_folder, exist_ok=True)\n",
    "\n",
    "        np.save(os.path.join(mrt_folder, f'{i}.npy'), augmented_mri_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jr003809-mrt',\n",
       " 'jr003529-mrt',\n",
       " 'jr005882-mrt',\n",
       " 'jr003642-mrt',\n",
       " 'jr005691-mrt',\n",
       " 'jr005990-mrt',\n",
       " 'jr003534-mrt',\n",
       " 'jr003912-mrt',\n",
       " 'jr009062-mrt',\n",
       " 'jr009039-mrt',\n",
       " 'jr003803-mrt',\n",
       " 'jr003260-mrt',\n",
       " 'jr003643-mrt',\n",
       " 'jr003525-mrt',\n",
       " 'jr009032-mr',\n",
       " 'jr003021-mrt',\n",
       " 'jr005643-mrt',\n",
       " 'jr005667-mrt',\n",
       " 'jr003376-mrt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/root/code/thesis/codeFolder/LatestDataInUse/t2_hr_spir_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usama",
   "language": "python",
   "name": "usama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
